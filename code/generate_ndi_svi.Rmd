---
title: "NDI and SVI"
author: 
- "Primary Programmer: Jiayi Zhou"
- "Contributors: Stephen P. Uong, Jeanette A. Stingone"
date: "10/27/2021"
output: 
  html_document:
    code_folding: show
    toc: TRUE
    toc_float: TRUE
    toc_depth: 6
---
<style type="text/css">

h1.title {
  text-align: center;
}

</style>
## Aim
In this RMD, we have documented the process of constructing an Neighborhood Deprivation Index (NDI) following a developed method. We have also imported the Social Vulnerability Index (SVI) data from the CDC and tested the correlation between NDI and the SVI on the  census-tract level in the New York City.

## Setup
We set the working directory to one folder up from the RMarkdown file.
```{r, setup}
knitr::opts_knit$set(root.dir = '..') 
```

```{r}
knitr::opts_chunk$set(echo = TRUE)
options(tigris_class = "sf")
```

```{r}
library(devtools)

library(ggbiplot)
library(stats)
library(factoextra)
library(cluster)

library(tidycensus)
library(tidyverse)

library(psych)
library(tigris)
library(sf)
library(Amelia)
library(patchwork)
library(rgdal)

library(viridis)
library(wesanderson)
```

## NDI Associated Variables:
Based on a review of literature, 23 census variables that have been used consistently to approximate neighborhood-level environments for possible inclusion in the deprivation index.
 
#### Candidate SEP variables (n = 23) 
Source: US Census American Communities Survey (2015-2019)       

**Education (among adults aged > 25)**        
% < High School	 	 
% BA or more        

**Employment (among adult labor force, aged 20-64)**        
% unemployed        
% males in labor force 	 	 
% females in labor force 	 	        

**Housing**       
% renter occupied (among occupied units)	 	 
% vacant housing units (among total housing units)	 	 
% crowded (> 1 occupant per room, among occupied housing units)       

**Occupation (among full-time, year-round civilian employed population)**       
% adults in management or professional occupations        

**Income**        
% households in poverty (< 200% Federal Poverty Line)	        
% Families w/ annual income < $35,000 (2009 inflation-adjusted)	 	    
% female householders with children aged < 18	 	        
% households w/ public assistance income	    
% households w/ Food Stamp benefits (in past 12 months)	 	    
Median household income (in the past 12 months)	 	    
% renter or owner housing costs in excess of 30% household income (in past 12 months)      

**Racial composition**      
% African American (non-Hispanic)       
% non-White (calculated as 1 - % non-Hispanic White population)         
% Hispanic          

**Residential Stability**       
% living in the same house one year ago			    
% Foreign-born			    
% not a U.S. citizen        

**Language**        
% speak English less than “very well” (among pop > 5 years old who speak a language other than English at home)	 	 

#### Check the ACS variables
```{r, eval=FALSE}
acs_19 <- load_variables(2019, "acs5", cache = TRUE)

#View(acs_19)
```

#### Write out All the Variables Names that will be needed from the ACS:
```{r}
edu_belowHS_male = sprintf("B15002_%0.3d",seq(3, 10, by = 1))
edu_belowHS_female = sprintf("B15002_%0.3d",seq(20, 27, by = 1))
edu_BA_more = c("B15002_015","B15002_016","B15002_017","B15002_018","B15002_032","B15002_033","B15002_034","B15002_035")
edu_var = c(edu_belowHS_female, edu_belowHS_male, edu_BA_more,"B15002_002", "B15002_019")

unempl_male = sprintf("B23001_%0.3d",seq(15, 71, by = 7))
unempl_female = sprintf("B23001_%0.3d",seq(101, 157, by = 7))
labor_force_male = sprintf("B23001_%0.3d",seq(11, 67, by = 7))
labor_force_female = sprintf("B23001_%0.3d",seq(97, 153, by = 7))
unempl_var = c("B23001_002", "B23001_088","B23001_001","B23001_003","B23001_089",
               labor_force_female,labor_force_male, unempl_male, unempl_female)


housing_var = c("B25003_001","B25002_001","B25002_003", "B25003_003",
                "B25014_001", "B25014_005", "B25014_006", "B25014_007",
                "B25014_011", "B25014_012", "B25014_013", "B25070_007",
                "B25070_008","B25070_009","B25070_010","B25070_011","B25070_001")

occup_var = c("C24010_001", "C24010_003","C24010_040")

poverty_var = c("B17010_001", "B17010_002",
                "B11005_007","B11005_010","B11005_001",
                "B19057_001","B19057_002",
                "B99221_002","B99221_001",
                "B19013_001",
                "B19001_001", "B19001_002",
                "B19001_003", "B19001_004", 
                "B19001_005", "B19001_006", "B19001_007")

racial_var = c("B03002_004", "B03002_003", "B03002_012", "B03002_001")

stability_var = c("B07007_001", "B07007_006", "B07007_003", "B07007_005")

language_var = c("B16005_001","B16005_007", "B16005_008","B16005_012","B16005_013",
                 "B16005_017", "B16005_018", "B16005_022", "B16005_023",
                 "B16005_029", "B16005_030", "B16005_034", "B16005_035",
                 "B16005_039", "B16005_040", "B16005_044", "B16005_045")

c_var = c(edu_var, unempl_var, housing_var, occup_var, poverty_var, racial_var,stability_var,language_var)
```

#### Pulling Census Data
We used an exclusion list to filter out the census tracts that does not pass the inclusion criteria. Of the original 2,167 census tracts in New York City (NYC), we excluded 51 tracts that had a population of less than twenty people and 30 tracts that had a population of at least twenty people but had at least one missing feature in the calculation of the NVI or the Neighborhood Deprivation Index (described later). The majority of the 30 census tracts were non-residential areas, such construction sites, parks, and areas with institutions. As a result, we included 2,086 census tracts in our development of the NVI.
```{r}
exclusion_table = read.csv("data/processed/EXCLUSION_LIST_20210628.csv")

view(exclusion_table)
```

#### Data Transformation
Considering the final NDI should be an index with the higher value indicating more deprivation, the value of the candidate variables should show the same pattern. Thus, we reverse coded measures that originally had smaller value associated with deprivation, such as:
* percent population with a college degree or higher
* percent male and female in labor force
* percent population in mangement 
* percent non-White population
* percent living in the same house for the past year
By doing this reverse coding, we can ensure that they were pointing in the same direction as the other candidate variables.

We also reverse coded and log transformed median household income to ensure normal distribution.
```{r}
#pulling data
nyc_data = 
  get_acs(geography = "tract", variables =c_var,
                    state = "NY",  
                    county = c('Bronx County', 'Kings County', 
                        'New York County', 'Queens County', 'Richmond County'),
                    year = 2019,
                    output = "wide")


total_left = exclusion_table %>% filter(flag_exclude_FINAL == 0) %>% select(GEOID)

total_left = as.vector(total_left$GEOID)

nyc_acs_data = nyc_data %>%
  filter(GEOID %in% total_left) %>% 
  mutate(pct_noHS = 
           (B15002_003E+B15002_004E+B15002_005E+B15002_006E+B15002_007E+B15002_008E+B15002_009E+B15002_010E+B15002_020E+B15002_021E+B15002_022E+B15002_023E+B15002_024E+B15002_025E+B15002_026E+B15002_027E)/(B15002_002E+B15002_019E),
         pct_BAmore = 
           1-((B15002_015E+B15002_016E+B15002_017E+B15002_018E+B15002_032E+B15002_033E+B15002_034E+B15002_035E)/(B15002_002E+B15002_019E)),
         pct_unempl = 
           (B23001_015E+B23001_022E+B23001_029E+B23001_036E+
            B23001_043E+B23001_050E+B23001_057E+B23001_064E+
            B23001_071E+B23001_101E+B23001_108E+B23001_115E+B23001_122E+
            B23001_129E+B23001_136E+B23001_143E+B23001_150E+B23001_157E)/
           (B23001_001E-B23001_003E-B23001_089E),
         pct_male_labor_force = 
           1-((B23001_011E+B23001_018E+B23001_025E+B23001_032E+B23001_039E+B23001_046E+B23001_053E+B23001_060E+B23001_067E)/(B23001_002E-B23001_003E)),
         pct_female_labor_force = 
           1-((B23001_097E+B23001_104E+B23001_111E+B23001_118E+B23001_125E+B23001_132E+B23001_139E+B23001_146E+B23001_153E)/(B23001_088E-B23001_089E)),
         pct_rented = 
           B25003_003E/B25003_001E,
         pct_vacant = B25002_003E/B25002_001E,
         pct_crowded = (B25014_005E+B25014_006E+B25014_007E+B25014_011E+B25014_012E+B25014_013E)/B25014_001E,
         pct_mgmt = 1-((C24010_003E+C24010_040E)/C24010_001E),
         pct_poverty = B17010_002E/B17010_001E,
         pct_FHH = (B11005_007E+B11005_010E)/B11005_001E,
         pct_under35K = (B19001_002E+B19001_003E+B19001_004E+B19001_005E+B19001_006E+B19001_007E)/B19001_001E,
         pct_pubassist = B19057_002E/B19057_001E,
         pct_foodstamp = B99221_002E/B99221_001E,
         median_HH_income = -log(B19013_001E),
         pct_30cost = 
           (B25070_007E+B25070_008E+B25070_009E+B25070_010E+B25070_011E)/B25070_001E,
         pct_Black = B03002_004E/B03002_001E,
         pct_nonWhite = 1-(B03002_003E/B03002_001E),
         pct_Hispanic = B03002_012E/B03002_001E,
         pct_E_notwell = (B16005_007E+B16005_008E+B16005_012E+B16005_013E+B16005_017E+B16005_018E+B16005_022E+B16005_023E+B16005_029E+B16005_030E+B16005_034E+B16005_035E+B16005_039E+B16005_040E+B16005_044E+B16005_045E)/B16005_001E,
         pct_samehouse = -B07007_006E/B07007_001E,
         pct_foreignborn = B07007_003E/B07007_001E,
         pct_notcitizen = B07007_005E/B07007_001E)%>% 
  mutate(NAME = gsub(" County, New York", "", NAME)) %>%
  select(GEOID, NAME,
         pct_noHS,pct_BAmore,
         pct_unempl, pct_male_labor_force,pct_female_labor_force,
         pct_rented, pct_vacant,pct_crowded,
         pct_mgmt, pct_poverty, pct_under35K, pct_FHH, pct_pubassist, pct_foodstamp,pct_30cost,
         median_HH_income,
         pct_Black,pct_Hispanic,pct_nonWhite,pct_E_notwell,
         pct_samehouse, pct_foreignborn, pct_notcitizen)

missmap(nyc_acs_data)

nyc_acs_data = nyc_acs_data %>% drop_na()

missmap(nyc_acs_data)
```

## Step 1: City Wide: Dimensionality Reduction
First city-wide PCA (starts with 24 candidate variables):         
a.	Variable manipulation: Z-standardize the percentages        
b.	Initial component extraction and eigenvalue calculation with all 24 variables included       
c.	Selected the number of components based on eigenvalues > 1        
d.	Varimax rotate the loading in the selected components (I used psych::principal(...,rotate="varimax") in R)        
e.	Inclusion criteria (according to Messer et al.): if a variable loaded above 0.25 in the first component, then keep        
f.	Exclusion criteria (according to Shmool et al.): if a variable loaded strongly (greater than 0.4 or smaller than -0.4) on more than one component, then delete        
g.	Tally all variables that are retained by accessing the initial city-wide PCA solution       

```{r}
values =
  nyc_acs_data %>% 
  select(pct_noHS,pct_BAmore,
         pct_unempl, pct_male_labor_force,pct_female_labor_force,
         pct_rented, pct_vacant,pct_crowded,
         pct_mgmt, pct_poverty, pct_under35K, pct_FHH, pct_pubassist, pct_foodstamp,pct_30cost,
         median_HH_income,
         pct_Black,pct_Hispanic,pct_nonWhite,pct_E_notwell,
         pct_samehouse, pct_foreignborn, pct_notcitizen)

missmap(values)
#values[values == 0] <- NA
```

```{r}
# compute variance of each variable
# will see standarization is needed
apply(values, 2, var, na.rm = TRUE)
```

```{r}
# create new data frame with centered variables
scaled_df = apply(values, 2, scale)
#scaled_df[is.na(scaled_df)] = 0  #assign 0 to NA values,.
head(scaled_df)
```

```{r}
# Calculate eigenvalues & eigenvectors
ndi_var.cov = cov(scaled_df)
ndi_var.eigen = eigen(ndi_var.cov) #PC1-5
str(ndi_var.eigen)
```

```{r}
pca_firstcitywide_rotated <- psych::principal(scaled_df, rotate="varimax", nfactors=5, scores=TRUE)
print(pca_firstcitywide_rotated$loadings[,1:5])
```
**Retained in the initial city-wide**         
pct_unempl,       
pct_rented,pct_crowded,       
pct_poverty,pct_under35K,pct_pubassist,median_HH_income,        
pct_nonWhite,pct_E_notwell        

## Step 2: Stratified PCA (5 boroughs)
Borough-stratified PCAs (starts with 24 candidate variables):       
a.	Repeat steps b-c described in the first city-wide PCA process       
b.	Inclusion criteria:       
    i.	Based on Messer et al.: If a variable not only loaded above 0.25 in at least one borough but also never loaded below 0.16 in any borough in the first component, then keep for the next inclusion assessment       
    ii.	Based on Shmool et al.: If a variable passed previous inclusion criteria (> 0.25 and never <0.16 in the first component), then they are included in this second selection step-> If a variable loaded greater than 0.4 or smaller than -0.4 in any component in two or more borough-level PCA solution, then keep for second city-wide PCA process **       
c.	Exclusion criteria: Same as before. If a variable loaded strongly (greater than 0.4 or smaller than -0.4) on more than one component, then delete        

#### Bronx County
```{r, eval=FALSE}
values_bronx=
  nyc_acs_data %>%
  filter(str_detect(GEOID, "^36005" )) %>% 
  select(pct_noHS,pct_BAmore,
pct_unempl,pct_male_labor_force, pct_female_labor_force, 
pct_rented,pct_vacant,pct_crowded,
pct_mgmt,
pct_poverty,pct_under35K,pct_FHH,pct_pubassist,pct_foodstamp,pct_30cost,median_HH_income,
pct_Black, pct_Hispanic,pct_nonWhite,pct_E_notwell,
pct_samehouse,pct_foreignborn, pct_notcitizen)

#values_bronx[values_bronx == 0] <- NA
```

```{r, eval=FALSE}
# compute variance of each variable
# will see standarization is needed
apply(values_bronx, 2, var, na.rm = TRUE)
```

```{r, eval=FALSE}
# create new data frame with centered variables
scaled_df_b = apply(values_bronx, 2, scale)
#scaled_df_b[is.na(scaled_df_b)] = 0  #assign 0 to NA values, no variance? not sure if ok.
head(scaled_df_b)
```

```{r, eval=FALSE}
# Calculate eigenvalues & eigenvectors
ndi_var_b.cov = cov(scaled_df_b)
ndi_var_b.eigen = eigen(ndi_var_b.cov) #PC5
str(ndi_var_b.eigen)
```

```{r, eval=FALSE}
pca_bronx_rotated <- psych::principal(scaled_df_b, rotate="varimax", nfactors=5, scores=TRUE)
print(pca_bronx_rotated$loadings[,1:5])
```
**Retain: Bronx**         
pct_noHS,pct_BAmore,        
pct_rented,       
pct_mgmt,       
pct_poverty,pct_under35K,pct_FHH,pct_pubassist,pct_30cost,median_HH_income,       
pct_notcitizen        

#### Kings County
```{r, eval=FALSE}
values_kings=
  nyc_acs_data %>%
  filter(str_detect(GEOID, "^36047" )) %>% 
  select(pct_noHS,pct_BAmore,
pct_unempl,pct_male_labor_force, pct_female_labor_force, 
pct_rented,pct_vacant,pct_crowded,
pct_mgmt,
pct_poverty,pct_under35K,pct_FHH,pct_pubassist,pct_foodstamp,pct_30cost,median_HH_income,
pct_Black, pct_Hispanic,pct_nonWhite,pct_E_notwell,
pct_samehouse,pct_foreignborn, pct_notcitizen)
  
#values_kings[values_kings == 0] <- NA
```


```{r, eval=FALSE}
# compute variance of each variable
# will see standarization is needed
apply(values_kings, 2, var, na.rm = TRUE)
```

```{r, eval=FALSE}
# create new data frame with centered variables
scaled_df_k = apply(values_kings, 2, scale)
#scaled_df_k[is.na(scaled_df_k)] = 0  #assign 0 to NA values, no variance? not sure if ok.
head(scaled_df_k)
```

```{r, eval=FALSE}
# Calculate eigenvalues & eigenvectors
ndi_var_k.cov = cov(scaled_df_k)
ndi_var_k.eigen = eigen(ndi_var_k.cov) #PC5
str(ndi_var_k.eigen)
```


```{r, eval=FALSE}
pca_kings_rotated <- psych::principal(scaled_df_k, rotate="varimax", nfactors=5, scores=TRUE)
print(pca_kings_rotated$loadings[,1:5])
```
**Retain: Kings**       
pct_unempl,         
pct_rented,       
pct_poverty,pct_pubassist,        
pct_Hispanic        

#### New York County
```{r, eval=FALSE}
values_NY=
  nyc_acs_data %>%
  filter(str_detect(GEOID, "^36061" )) %>% 
  select(pct_noHS,pct_BAmore,
pct_unempl,pct_male_labor_force, pct_female_labor_force, 
pct_rented,pct_vacant,pct_crowded,
pct_mgmt,
pct_poverty,pct_under35K,pct_FHH,pct_pubassist,pct_foodstamp,pct_30cost,median_HH_income,
pct_Black, pct_Hispanic,pct_nonWhite,pct_E_notwell,
pct_samehouse,pct_foreignborn, pct_notcitizen)

  missmap(values_NY)
#values_NY[values_NY == 0] <- NA
```

```{r, eval=FALSE}
# compute variance of each variable
# will see standarization is needed
apply(values_NY, 2, var, na.rm = TRUE)
```

```{r, eval=FALSE}
# create new data frame with centered variables
scaled_df_ny = apply(values_NY, 2, scale)
#scaled_df_ny[is.na(scaled_df_ny)] = 0  #assign 0 to NA values, no variance? not sure if ok.
head(scaled_df_ny)
```

```{r, eval=FALSE}
# Calculate eigenvalues & eigenvectors
ndi_var_ny.cov = cov(scaled_df_ny)
ndi_var_ny.eigen = eigen(ndi_var_ny.cov) #PC4
str(ndi_var_ny.eigen)
```

```{r, eval=FALSE}
pca_ny_rotated <- psych::principal(scaled_df_ny, rotate="varimax", nfactors=4, scores=TRUE)
print(pca_ny_rotated$loadings[,1:4])
```
**Retain: New York**        
pct_BAmore,       
pct_unempl,       
pct_crowded,        
pct_mgmt,             
pct_poverty,pct_FHH,pct_pubassist,median_HH_income,       
pct_Black,pct_nonWhite        


#### Queens County
```{r, eval=FALSE}
values_queens=
  nyc_acs_data %>%
  filter(str_detect(GEOID, "^36081" )) %>% 
  select(pct_noHS,pct_BAmore,
pct_unempl,pct_male_labor_force, pct_female_labor_force, 
pct_rented,pct_vacant,pct_crowded,
pct_mgmt,
pct_poverty,pct_under35K,pct_FHH,pct_pubassist,pct_foodstamp,pct_30cost,median_HH_income,
pct_Black, pct_Hispanic,pct_nonWhite,pct_E_notwell,
pct_samehouse,pct_foreignborn, pct_notcitizen)

  missmap(values_queens)
#values_queens[values_queens == 0] <- NA
```

```{r, eval=FALSE}
# compute variance of each variable
# will see standarization is needed
apply(values_queens, 2, var, na.rm = TRUE)
```

```{r, eval=FALSE}
# create new data frame with centered variables
scaled_df_q = apply(values_queens, 2, scale)
#scaled_df_q[is.na(scaled_df_q)] = 0  #assign 0 to NA values, no variance? not sure if ok.
head(scaled_df_q)
```

```{r, eval=FALSE}
# Calculate eigenvalues & eigenvectors
ndi_var_q.cov = cov(scaled_df_q)
ndi_var_q.eigen = eigen(ndi_var_q.cov) #PC6
str(ndi_var_q.eigen)
```

```{r, eval=FALSE}
pca_queens_rotated <- psych::principal(scaled_df_q, rotate="varimax", nfactors=6, scores=TRUE)
print(pca_queens_rotated$loadings[,1:6])
```
**Retain: Queens**        
pct_noHS,       
pct_crowded,        
pct_poverty,median_HH_income,       
pct_Hispanic,pct_E_notwell,       
pct_foreignborn, pct_notcitizen       

#### Richmond County
```{r, eval=FALSE}
values_Richmond=
  nyc_acs_data %>%
  filter(str_detect(GEOID, "^36085" )) %>% 
  select(pct_noHS,pct_BAmore,
pct_unempl,pct_male_labor_force, pct_female_labor_force, 
pct_rented,pct_vacant,pct_crowded,
pct_mgmt,
pct_poverty,pct_under35K,pct_FHH,pct_pubassist,pct_foodstamp,pct_30cost,median_HH_income,
pct_Black, pct_Hispanic,pct_nonWhite,pct_E_notwell,
pct_samehouse,pct_foreignborn, pct_notcitizen)
#values_Richmond[values_Richmond == 0] <- NA
```

```{r, eval=FALSE}
# compute variance of each variable
# will see standarization is needed
apply(values_Richmond, 2, var, na.rm = TRUE)
```

```{r, eval=FALSE}
# create new data frame with centered variables
scaled_df_r = apply(values_Richmond, 2, scale)
#scaled_df_r[is.na(scaled_df_r)] = 0  #assign 0 to NA values, no variance? not sure if ok.
head(scaled_df_r)
```

```{r, eval=FALSE}
# Calculate eigenvalues & eigenvectors
ndi_var_r.cov = cov(scaled_df_r)
ndi_var_r.eigen = eigen(ndi_var_r.cov) #PC6
str(ndi_var_r.eigen)
```

```{r, eval=FALSE}
pca_richmond_rotated <- psych::principal(scaled_df_r, rotate="varimax", nfactors=6, scores=TRUE)
print(pca_richmond_rotated$loadings[,1:6])
```
**Retain: Richmond**        
pct_male_labor_force,         
pct_rented,pct_vacant,pct_crowded,        
pct_poverty,pct_under35K,pct_FHH,pct_pubassist,median_HH_income,        
pct_Black,pct_E_notwell,        
pct_notcitizen        

## Succesive PCA Summary:
I have tallied all variables that retained from each step here. To see a more detailed table, please refer to the supplemental Table 1 of the paper.        


**Retained in the initial city-wide** (only > 0.4 or < -0.4 in the first component, and cannot be > 0.4 or < -0.4 in more then one component):       

pct_unempl,       
pct_rented,pct_crowded,       
pct_poverty,pct_under35K,pct_pubassist,median_HH_income,        
pct_nonWhite,pct_E_notwell        
    

*After doing the stratified PAC, we have the following variables loaded strongly borough-level PCA  solutions:       
**Bronx**         
pct_noHS,pct_BAmore,        
pct_rented,       
pct_mgmt,       
pct_poverty,pct_under35K,pct_FHH,pct_pubassist,pct_30cost,median_HH_income,       
pct_notcitizen        

**Kings**       
pct_unempl,         
pct_rented,       
pct_poverty,pct_pubassist,        
pct_Hispanic        

**New York**        
pct_BAmore,       
pct_unempl,       
pct_crowded,        
pct_mgmt,       
pct_poverty,pct_FHH,pct_pubassist,median_HH_income,       
pct_Black,pct_nonWhite        

**Queens**        
pct_noHS,       
pct_crowded,        
pct_poverty,median_HH_income,       
pct_Hispanic,pct_E_notwell,       
pct_foreignborn, pct_notcitizen       

**Richmond**        
pct_male_labor_force,         
pct_rented,pct_vacant,pct_crowded,        
pct_poverty,pct_under35K,pct_FHH,pct_pubassist,median_HH_income,        
pct_Black,pct_E_notwell,        
pct_notcitizen        

**more then 2 boroughs**:       
pct_noHS,pct_BAmore,        
pct_unempl,       
pct_rented,pct_crowded,       
pct_mgmt,       
pct_poverty,pct_under35K,pct_FHH,pct_pubassist,median_HH_income,        
pct_Hispanic, pct_Black, pct_E_notwell        
pct_notcitizen        


**less then 0.16:**       
bronx:(pct_Black)       
kings:(pct_notcitizen)        
queens:(pct_unempl,pct_FHH,pct_pubassist)       


**Variables that should be included in the second city-wide:(only > 0.4 or < -0.4 in one component)**       
_from stratified_       
pct_noHS,pct_BAmore,        
pct_rented,pct_crowded,       
pct_mgmt,       
pct_poverty,pct_under35K,median_HH_income,        
pct_Hispanic, pct_E_notwell       
  +       
_from first city-wide_        
pct_unempl,       
pct_rented,pct_crowded,       
pct_poverty,pct_under35K,pct_pubassist,median_HH_income,        
pct_nonWhite,pct_E_notwell        


**NEW TOTAL**       
pct_noHS,pct_BAmore,        
pct_unempl，        
pct_rented,pct_crowded,       
pct_mgmt,       
pct_poverty,pct_under35K,pct_pubassist, median_HH_income,       
pct_nonWhite,pct_Hispanic, pct_E_notwell        

## Step 3: Second City-wide:
Second city-wide PCA (starts with 12 variables selected in the initial city-wide PCA process and the borough-level PCA process) :        

a.	Repeat steps b-f described in the first city-wide PCA process (used the same inclusion and exclusion criteria as the first city wide PAC since cannot find description on what Messer or Shmool did):
```{r, eval=FALSE}
values_s =
  nyc_acs_data %>% 
  select(pct_noHS,pct_BAmore,
pct_unempl,
pct_rented,pct_crowded,
pct_mgmt,
pct_poverty,pct_under35K,pct_pubassist, median_HH_income,
pct_nonWhite,pct_Hispanic, pct_E_notwell)

missmap(values_s)
#values[values == 0] <- NA(0% are still meaningful)
```

```{r, eval=FALSE}
# compute variance of each variable
# will see standarization is needed
apply(values_s, 2, var, na.rm = TRUE)
```

```{r, eval=FALSE}
# create new data frame with centered variables
scaled_df_s = apply(values_s, 2, scale)
#scaled_df[is.na(scaled_df)] = 0  #assign 0 to NA values,.
head(scaled_df_s)
```

```{r, eval=FALSE}
# Calculate eigenvalues & eigenvectors
ndi_var_s.cov = cov(scaled_df_s)
ndi_var_s.eigen = eigen(ndi_var_s.cov) #PC3
str(ndi_var_s.eigen)
```

```{r, eval=FALSE}
pca_secondcitywide_rotated <- psych::principal(scaled_df_s, rotate="varimax", nfactors=3, scores=TRUE)
print(pca_secondcitywide_rotated$loadings[,1:3])
```
**after omition:**        
pct_BAmore,       
pct_unempl，        
pct_mgmt,       
pct_poverty,pct_under35K,pct_pubassist,       
pct_nonWhite        


The final 7 features of deprivation were used to re-ran the final PCA and create the final NDI.       

## Step 4: Final City-Wide PCA
Final Index construction (starts with 7 variables: % BA or more,% unemployed, % adults in management or professional occupations ,% households in poverty (< 200% Federal Poverty Line),% Families w/ annual income < $35,000 (2019 inflation-adjusted),% households w/ public assistance income,% non-White)       

a.	Re-run the PCA process with the 7 variables       
b.	Extract the un-rotated loading in the first component as the NDI        
```{r}
# create new data frame with centered variables
NDI_df = nyc_acs_data %>% 
  select(pct_BAmore,
pct_unempl,
pct_mgmt,
pct_poverty,pct_under35K,pct_pubassist,
pct_nonWhite)

missmap(NDI_df)
scaled_ndi_df = apply(NDI_df, 2, scale)
#scaled_ndi_df[is.nan(scaled_ndi_df)] = 0  #assign 0 to NA values, no variance? not sure if ok.
head(scaled_ndi_df)

summary(NDI_df)

summary(scaled_ndi_df)
```

```{r}
# Calculate eigenvalues & eigenvectors
ndi.cov = cov(scaled_ndi_df)
ndi.eigen = eigen(ndi.cov)
str(ndi.eigen)
```

```{r}
PVE = ndi.eigen$values / sum(ndi.eigen$values) #61%
PVE

PVE_initial = ndi_var.eigen$values /sum(ndi_var.eigen$values) #53%
PVE_initial
```

```{r}
pca_ndi_rotated = psych::principal(scaled_ndi_df, rotate="none", nfactors=1, scores=TRUE)
NDI_score = pca_ndi_rotated$scores[,1]

NDI_score = as.matrix(NDI_score)
```

```{r}
summary(NDI_score)
```

```{r}
NDI_2086=
  data.frame(GEOID = nyc_acs_data[,1], NAME = nyc_acs_data[,2], NDI_score) %>%
  separate(NAME, 
           into = c("Tract", "County"), 
           sep = ",") %>% 
  mutate(County = str_trim(County), FIPS = GEOID) %>% 
  select(GEOID, FIPS, Tract, County, NDI_score)

NDI_2086$FIPS = substr(NDI_2086$FIPS, 0, 5)

head(NDI_2086)
```

#### Save the NDI data output
```{r}
#write.csv(NDI_2086, "data/raw/NDI.NYC.2086t.csv")
```

## Scale and Visualize the NDI:
Here we transformed the continues NDI into quartiles. Having NDI as a categorical variable will produce a map that have better color contract. Moreover, since we are aiming to compare our NDI to CDC's SVI, it is necessary to transform these two indices on to the same scale. 
```{r}
NDI_with_scaled_score = NDI_2086 %>% 
  dplyr::mutate(NDI_scaled= dplyr::ntile(NDI_score, 4))
```

Check summary statistics
```{r}
summary(NDI_with_scaled_score)
```

#### Check the NDI distribution
In order to check the validity of the NDI that we have calculated, we mapped the NDI scores across NYC. The maps produced here were not included in our manuscript. These maps were made for the quality control purposes. 
```{r}
library(nycgeo)
```

```{r}
map_ndi_with_score = nyc_boundaries(geography = "tract") %>% 
  left_join(NDI_2086, by = c("geoid" = "GEOID")) %>% 
  ggplot() +
  geom_sf(aes(fill = NDI_score),color = NA) +
  theme_minimal() + 
  theme(axis.text = element_blank(),legend.position = "bottom") +
  theme(plot.background = element_rect(fill = "lightcyan")) +
  scale_fill_gradient(low = "OldLace", high = "firebrick4")+
  labs(fill = "NDI",
       title = "Neighborhood Deprivation Index",
       subtitle = "unscaled",
       caption = "Source: 2015-2019 5-year ACS estimates")
```

```{r}
map_ndi_with_scaled_score = nyc_boundaries(geography = "tract") %>% 
  left_join(NDI_with_scaled_score, by = c("geoid" = "GEOID")) %>% 
  ggplot() +
  geom_sf(aes(fill = NDI_scaled),color = NA) +
  theme_minimal() + 
  theme(axis.text = element_blank(),legend.position = "bottom") +
  theme(plot.background = element_rect(fill = "lightcyan")) +
  scale_fill_gradient(low = "OldLace", high = "firebrick4")+
  labs(fill = "NDI",
       title = "Neighborhood Deprivation Index",
       subtitle = "scaled",
       caption = "Source: 2015-2019 5-year ACS estimates")
```

```{r}
map_ndi_with_score + map_ndi_with_scaled_score
```

#### Barplot
```{r}
City_score = NDI_2086 %>% 
  select(NDI_score) %>% 
  mutate(County = "City-wide")

Stratified = NDI_2086 %>% 
  select(NDI_score, County)


NDI_box = rbind(City_score,Stratified)

NDI_box$County <- factor(NDI_box$County, levels=c("City-wide","New York", "Richmond","Kings", "Queens","Bronx"))



ggplot(NDI_box, aes(x = County, y = NDI_score))+
  geom_boxplot(fill = "OldLace") +
    stat_summary(
    aes(label=sprintf("%1.1f", ..y..), color = "red"),
    geom="text", 
    fun = quantile,
    #fun = function(y) boxplot.stats(y)$stats,
    position=position_nudge(x=0.2), 
    size=3.0, show.legend=FALSE)+
    stat_summary(fun=mean, colour="darkred", geom="point", 
               shape=16, size=2, show.legend=FALSE)+
  coord_flip() +
  theme_minimal()+
  theme(plot.background = element_rect(fill = "lightcyan")) +
  labs(title = "Neighborhood Deprivation Score Distribution")
```

## SVI
Import the CDC SVI data file. The variable "RPL_THEMES" is the SVI.
```{r}
SDI_df = read_csv("data/raw/svi.csv") %>% 
  mutate(FIPS = as.character(FIPS)) %>% 
  filter(FIPS %in% NDI_2086$GEOID) %>% 
  select(FIPS, LOCATION, COUNTY, RPL_THEMES) %>% 
  rename(GEOID = FIPS) %>% 
  filter(RPL_THEMES != -999.0000)
```

1. Scale the SVI in the same way as scaling the NDI. This scaled score will be used for future mapping
2. Conducted a spearman correlation test testing the association between the continouse NDI and SVI. 
```{r}
SDI = scale(SDI_df$RPL_THEMES)

summary(SDI)

SDI_df =
  data.frame(GEOID = SDI_df[,1], SDI)

SDI_scaled = SDI_df %>% 
  dplyr::mutate(SDI_s = dplyr::ntile(SDI, 4))

summary(SDI_df)

NDI_c = join(NDI_2086, SDI_df, by = "GEOID") %>% 
  pull(NDI_score) %>% as.numeric()

SDI_c = join(NDI_2086, SDI_df, by = "GEOID") %>% 
  pull(SDI) %>% as.numeric()

cor.test(NDI_c, SDI_c, alternative = "two.sided", method = "spearman", conf.level = 0.95)
```
The correlation coefficient between NDI and SVI is 0.86. They are correlated.

#### Visualization: Check the SVI distribution
```{r}
map_sdi = nyc_boundaries(geography = "tract") %>% 
  left_join(SDI_df, by = c("geoid" = "GEOID")) %>% 
  ggplot() +
  geom_sf(aes(fill = SDI),color = NA) +
  theme_minimal() + 
  theme(axis.text = element_blank(),legend.position = "bottom") +
  scico::scale_fill_scico(palette = "bilbao") +
  theme(plot.background = element_rect(fill = "lightcyan")) +
  scale_fill_gradient(low = "White", high = "firebrick4")+
  labs(fill = "SDI",
       title = "Social Vulnerability Index",
       subtitle = "unscaled",
       caption = "Source: 2018 CDC/ATSDR SVI Data")
```

```{r}
map_scaled_sdi = nyc_boundaries(geography = "tract") %>% 
  left_join(SDI_scaled, by = c("geoid" = "GEOID")) %>% 
  ggplot() +
  geom_sf(aes(fill = SDI_s),color = NA, ) +
  theme_minimal() + 
  theme(axis.text = element_blank(),legend.position = "bottom") +
  theme(plot.background = element_rect(fill = "lightcyan")) +
  scico::scale_fill_scico(palette = "bilbao") +
  scale_fill_gradient(low = "OldLace", high = "firebrick4")+
  labs(fill = "SDI",
       title = "Social Vulnerability Index",
       subtitle = "scaled",
       caption = "Source: 2018 CDC/ATSDR SVI Data")
```

## NDI vs SVI Maps
```{r}
(map_ndi_with_score + map_sdi)/(map_ndi_with_scaled_score + map_scaled_sdi)
```

## Result analysis: First Component Loadings
In this section, we will check the county-specific and city-wide feature loadings on the first principal component.
```{r}
c_city_wide = pca_ndi_rotated$loadings[,1]

#pca_ndi_income$loadings[,1]
```


#### Bronx：First Component Loading
```{r}
Bronx=
  nyc_acs_data %>%
  filter(str_detect(GEOID, "^36005" )) %>% 
  select(pct_BAmore,pct_unempl,pct_mgmt,pct_poverty,pct_under35K,pct_pubassist,pct_nonWhite)
```

```{r}
pca_Bronx_rotated <- psych::principal(Bronx, rotate="none", nfactors=1, scores=TRUE)
c_bronx = pca_Bronx_rotated$loadings[,1]
print(c_bronx)
```


#### Kings
```{r}
Kings=
  nyc_acs_data %>%
  filter(str_detect(GEOID, "^36047" )) %>% 
  select(pct_BAmore,pct_unempl,pct_mgmt,pct_poverty,pct_under35K,pct_pubassist,pct_nonWhite)
```

```{r}
pca_kings_rotated <- psych::principal(Kings, rotate="none", nfactors=1, scores=TRUE)
c_kings = pca_kings_rotated$loadings[,1]
print(c_kings)
```


#### NY
```{r}
NY=
  nyc_acs_data %>%
  filter(str_detect(GEOID, "^36061" )) %>% 
  select(pct_BAmore,pct_unempl,pct_mgmt,pct_poverty,pct_under35K,pct_pubassist,pct_nonWhite)
```

```{r}
pca_ny_rotated <- psych::principal(NY, rotate="none", nfactors=1, scores=TRUE)
c_ny = pca_ny_rotated$loadings[,1]
print(c_ny)
```

#### Queens
```{r}
Queens=
  nyc_acs_data %>%
  filter(str_detect(GEOID, "^36081" )) %>% 
  select(pct_BAmore,pct_unempl,pct_mgmt,pct_poverty,pct_under35K,pct_pubassist,pct_nonWhite)
```

```{r}
pca_queens_rotated <- psych::principal(Queens, rotate="none", nfactors=1, scores=TRUE)
c_queens = pca_queens_rotated$loadings[,1]
print(c_queens)
```

#### Richmond
```{r}
Richmond=
  nyc_acs_data %>%
  filter(str_detect(GEOID, "^36085" )) %>% 
  select(pct_BAmore,pct_unempl,pct_mgmt,pct_poverty,pct_under35K,pct_pubassist,pct_nonWhite)
#values_Richmond[values_Richmond == 0] <- NA
```

```{r}
pca_richmond_rotated <- psych::principal(Richmond, rotate="none", nfactors=1, scores=TRUE)
c_richmond = pca_richmond_rotated$loadings[,1]
print(c_richmond)
```

```{r}
r_prop_var = c(67.4,55.8,79.1,48.9,64.2,61.4)
```

#### Comparison Table: First Component Loadings
```{r}
library(knitr)
```

```{r}
df = data.frame(c_bronx,c_kings,c_ny,c_queens,c_richmond, c_city_wide) %>% rbind(r_prop_var)
new_df = as.data.frame(lapply(df,round, 3))
```

```{r}
df1 = round(max(df[1,]) - min(df[1,]), digits = 3)
df2 = round(max(df[2,]) - min(df[2,]), digits = 3)
df3 = round(max(df[3,]) - min(df[3,]), digits = 3)
df4 = round(max(df[4,]) - min(df[4,]), digits = 3)
df5 = round(max(df[5,]) - min(df[5,]), digits = 3)
df6 = round(max(df[6,]) - min(df[6,]), digits = 3)
df7 = round(max(df[7,]) - min(df[7,]), digits = 3)


difference = c(df1,df2,df3,df4,df5,df6,df7," ")

loading_comparison = new_df %>% cbind(difference)
row.names(loading_comparison) = c("% B.S./B.A. or higher","% Unempolyment", "% Management Occupation",
                                  "% Households in Poverty","% Households with annual income < $35,000", 
                                  "% Households receving public assistance",
                                  "% Non-Hispanic non-White", "% Variance Explained")
colnames(loading_comparison) = c("Bronx","Kings","New York", "Queens", "Richmond","City-wide Index","Loading Difference")

loading_comparison %>% kable(caption = "Supplemental Table 3. Comparison of Borough-specific and City-wide first principal component deprivation score loadings")

```
This result is save as the Supplemental table 3 in the manualscript.